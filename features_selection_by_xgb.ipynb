{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subaevdi/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import itertools\n",
    "\n",
    "from subprocess import check_output\n",
    "from pyfm import pylibfm\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 25\n",
    "\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавляем OneHotEncoder для категориальных фич\n",
      "Добавляем PCA ICA\n",
      "Добавляем пары\n",
      "Добавляем Кластарезацию по X0\n",
      "train.shape= (4209, 379) df shape =  (8418, 2027)\n",
      "feat_ohe\n",
      "feat_pca\n",
      "feat_ica\n",
      "feat_pairs_in_top\n",
      "feat_clust\n",
      "time: 4.82 s\n"
     ]
    }
   ],
   "source": [
    "%run -i create_df.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_fit(X_train, y_train, X_test, columns):\n",
    "    num_boost_rounds = 1200\n",
    "    \n",
    "    xgb_params = { \n",
    "        'eta': 0.005,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.8,\n",
    "        'min_child_weight': 25,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric': 'rmse',\n",
    "        'base_score': np.mean(y_train), # base prediction = mean(target)\n",
    "        'silent': 1,\n",
    "        'tree_method':'hist',\n",
    "        'seed':42,\n",
    "    #    'gamma': 0.05,\n",
    "        'alpha':0.3\n",
    "    }\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[columns], y_train)\n",
    "    dtest = xgb.DMatrix(X_test[columns])\n",
    "    \n",
    "    \n",
    "    # train model\n",
    "    model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
    "    y_pred = model.predict(dtest)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отобор признаков. Удаление с конца\n",
    "1. Обучить модель\n",
    "2. Провести кросс валидацию\n",
    "3. Удалить из списка худший признак\n",
    "4. Провести кросс валидацию на новом списке\n",
    "5. Сравнить результат 2. и 4. если есть улучшение, то убрать признак, иначе оставить.\n",
    "6. Взять следующий худший признак и перейти к шагу 2.\n",
    "\n",
    "feat_ohe - список всех признаков  \n",
    "feat_current - текущий список модели  \n",
    "\n",
    "feat\\_import - списко признаков в порядке возрастания imp   \n",
    "feat_сhecked - проверенные признаки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subaevdi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV  8.89796566667\n",
      "ohe_56 add 8.89 8.91 delta = -0.017\n",
      "ohe_91 del 8.90 8.89 delta = 0.006\n",
      "ohe_181 add 8.89 8.89 delta = -0.001\n",
      "ohe_194 del 8.89 8.89 delta = 0.002\n",
      "ohe_57 add 8.89 8.89 delta = -0.001\n",
      "ohe_143 del 8.91 8.89 delta = 0.017\n",
      "ohe_73 add 8.89 8.89 delta = -0.003\n",
      "ohe_189 add 8.89 8.90 delta = -0.010\n",
      "ohe_85 del 8.89 8.89 delta = 0.003\n",
      "ohe_158 del 8.89 8.88 delta = 0.005\n",
      "ohe_31 add 8.88 8.89 delta = -0.012\n",
      "ohe_48 del 8.88 8.88 delta = 0.002\n",
      "ohe_204 add 8.88 8.89 delta = -0.010\n",
      "ohe_144 add 8.88 8.88 delta = -0.005\n",
      "ohe_191 add 8.88 8.88 delta = -0.005\n",
      "ohe_8 add 8.88 8.89 delta = -0.012\n",
      "ohe_10 add 8.88 9.07 delta = -0.192\n",
      "ohe_187 add 8.88 8.88 delta = -0.006\n",
      "ohe_177 add 8.88 8.89 delta = -0.015\n",
      "ohe_160 add 8.88 8.89 delta = -0.009\n",
      "ohe_142 add 8.88 8.89 delta = -0.014\n",
      "ohe_205 del 8.88 8.87 delta = 0.007\n",
      "ohe_75 add 8.87 8.87 delta = -0.001\n",
      "ohe_80 add 8.87 8.87 delta = -0.005\n",
      "ohe_53 add 8.87 8.87 delta = -0.000\n",
      "ohe_135 add 8.87 8.87 delta = -0.002\n",
      "ohe_6 add 8.87 8.90 delta = -0.034\n",
      "ohe_163 add 8.87 8.88 delta = -0.011\n",
      "ohe_79 add 8.87 8.88 delta = -0.009\n",
      "ohe_78 add 8.87 8.88 delta = -0.010\n",
      "ohe_200 add 8.87 8.87 delta = -0.005\n",
      "ohe_176 add 8.87 8.87 delta = -0.001\n",
      "ohe_118 add 8.87 8.88 delta = -0.014\n",
      "ohe_15 add 8.86 8.89 delta = -0.025\n",
      "ohe_184 add 8.86 8.88 delta = -0.018\n",
      "ohe_134 add 8.86 8.88 delta = -0.019\n",
      "ohe_76 add 8.86 8.89 delta = -0.028\n",
      "ohe_18 add 8.87 8.88 delta = -0.008\n",
      "ohe_185 del 8.87 8.87 delta = 0.006\n",
      "ohe_159 del 8.87 8.86 delta = 0.006\n",
      "ohe_165 add 8.86 8.87 delta = -0.005\n",
      "ohe_136 add 8.86 8.88 delta = -0.014\n",
      "ohe_147 del 8.86 8.86 delta = 0.002\n",
      "ohe_9 del 8.86 8.86 delta = 0.002\n",
      "ohe_208 add 8.86 8.86 delta = -0.001\n",
      "ohe_161 del 8.86 8.85 delta = 0.005\n",
      "ohe_0 del 8.85 8.85 delta = 0.006\n",
      "ohe_169 add 8.85 8.85 delta = -0.008\n",
      "ohe_46 add 8.85 8.98 delta = -0.135\n",
      "ohe_183 add 8.85 8.85 delta = -0.005\n",
      "ohe_186 add 8.85 8.85 delta = -0.006\n",
      "ohe_99 add 8.85 8.85 delta = -0.004\n",
      "ohe_110 add 8.85 8.85 delta = -0.007\n",
      "ohe_23 del 8.85 8.85 delta = 0.001\n",
      "ohe_36 add 8.85 8.99 delta = -0.139\n",
      "ohe_63 add 8.84 8.84 delta = -0.002\n",
      "ohe_69 add 8.84 8.84 delta = -0.004\n",
      "ohe_132 add 8.84 8.85 delta = -0.009\n",
      "ohe_199 add 8.84 8.84 delta = -0.003\n",
      "ohe_182 add 8.84 8.84 delta = -0.003\n",
      "ohe_148 add 8.84 8.86 delta = -0.018\n",
      "ohe_52 add 8.84 8.96 delta = -0.117\n",
      "ohe_40 add 8.84 9.01 delta = -0.167\n",
      "ohe_89 add 8.84 8.85 delta = -0.008\n",
      "ohe_197 add 8.84 8.85 delta = -0.007\n",
      "ohe_62 del 8.84 8.84 delta = 0.000\n",
      "ohe_26 add 8.84 8.85 delta = -0.009\n",
      "ohe_49 add 8.85 9.02 delta = -0.169\n",
      "ohe_192 del 8.85 8.85 delta = 0.001\n",
      "ohe_133 del 8.85 8.84 delta = 0.004\n",
      "ohe_166 add 8.84 8.85 delta = -0.003\n",
      "ohe_203 add 8.84 8.85 delta = -0.004\n",
      "ohe_32 add 8.84 8.98 delta = -0.138\n",
      "ohe_41 add 8.84 8.99 delta = -0.151\n",
      "ohe_190 add 8.84 8.85 delta = -0.004\n",
      "ohe_54 add 8.84 8.84 delta = -0.001\n",
      "ohe_115 del 8.85 8.85 delta = 0.000\n",
      "ohe_151 add 8.85 8.85 delta = -0.000\n",
      "ohe_45 add 8.85 8.90 delta = -0.049\n",
      "ohe_50 add 8.85 9.08 delta = -0.235\n",
      "ohe_207 del 8.85 8.85 delta = 0.003\n",
      "ohe_34 del 8.85 8.84 delta = 0.002\n",
      "ohe_60 add 8.84 8.85 delta = -0.002\n",
      "ohe_130 del 8.85 8.84 delta = 0.005\n",
      "ohe_174 del 8.84 8.84 delta = 0.005\n",
      "ohe_180 add 8.84 8.84 delta = -0.000\n",
      "ohe_109 del 8.84 8.84 delta = 0.001\n",
      "ohe_77 del 8.84 8.84 delta = 0.006\n",
      "ohe_164 add 8.84 8.84 delta = -0.007\n",
      "ohe_196 add 8.84 8.84 delta = -0.007\n",
      "ohe_202 add 8.84 8.84 delta = -0.007\n",
      "ohe_66 add 8.84 8.84 delta = -0.002\n",
      "ohe_170 add 8.84 8.86 delta = -0.028\n",
      "ohe_122 add 8.84 8.84 delta = -0.009\n",
      "ohe_51 add 8.84 8.97 delta = -0.135\n",
      "ohe_117 del 8.84 8.83 delta = 0.004\n",
      "ohe_209 del 8.83 8.83 delta = 0.003\n",
      "ohe_149 add 8.83 8.83 delta = -0.004\n",
      "ohe_74 add 8.83 8.83 delta = -0.003\n",
      "ohe_195 add 8.83 8.83 delta = -0.004\n",
      "ohe_123 add 8.83 8.84 delta = -0.006\n",
      "ohe_39 add 8.83 8.85 delta = -0.018\n",
      "ohe_24 add 8.83 9.34 delta = -0.507\n",
      "ohe_72 del 8.83 8.82 delta = 0.006\n",
      "ohe_11 add 8.82 8.86 delta = -0.039\n",
      "Done!\n",
      "time: 32min 1s\n"
     ]
    }
   ],
   "source": [
    "columns = feat_ohe\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = df[ix_train]\n",
    "\n",
    "num_boost_rounds = 1500\n",
    "    \n",
    "xgb_params = { \n",
    "    'eta': 0.01,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.9,\n",
    "    'min_child_weight': 20,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'maximize':False,\n",
    "    'base_score': np.mean(y_train), # base prediction = mean(target)\n",
    "    'silent': 1,\n",
    "    'tree_method':'hist',\n",
    "    'seed':42,\n",
    "#    'gamma': 0.05,\n",
    "    'alpha':0.1\n",
    "}\n",
    "\n",
    "feat_checked = list()\n",
    "dtrain = xgb.DMatrix(X[columns], y)\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_rounds)\n",
    "t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "rmse = t.iloc[-1,0]\n",
    "\n",
    "print('CV ', t.iloc[-1,0])\n",
    "imp = model.get_fscore()\n",
    "feat_model = list(pd.DataFrame({'feat':list(imp.keys()),  'imp':list(imp.values())},\n",
    "             ).sort_values('imp')['feat'].values)\n",
    "feat_current = list(set(feat_model) - set(feat_checked))\n",
    "\n",
    "\n",
    "while len(feat_current) > 0:\n",
    "    # \n",
    "    dtrain = xgb.DMatrix(X[feat_checked + feat_current], y)\n",
    "    model = xgb.train(xgb_params, dtrain, num_boost_rounds)\n",
    "    t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    rmse = t.iloc[-1,0]\n",
    "    \n",
    "    imp = model.get_fscore()\n",
    "    feat_model = list(pd.DataFrame({'feat':list(imp.keys()),  'imp':list(imp.values())},\n",
    "                 ).sort_values('imp')['feat'].values)\n",
    "    feat_current = list(set(feat_model) - set(feat_checked))\n",
    "    feat = feat_current[0]\n",
    "    \n",
    "    # Проверка без признака\n",
    "    dtrain = xgb.DMatrix(X[feat_checked + feat_current[1:]], y)\n",
    "    t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    rmse_new = t.iloc[-1,0]\n",
    "\n",
    "    if rmse_new <= rmse:\n",
    "        print(feat, 'del {:.2f} {:.2f} delta = {:.3f}'.format(rmse, rmse_new, rmse - rmse_new))\n",
    "        feat_current = feat_current[1:]\n",
    "    else:\n",
    "        print(feat, 'add {:.2f} {:.2f} delta = {:.3f}'.format(rmse, rmse_new, rmse - rmse_new))\n",
    "        feat_checked.append(feat)\n",
    "        feat_current = feat_current[1:]\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savind ohe list...\n",
      "time: 2.94 ms\n"
     ]
    }
   ],
   "source": [
    "model_file = './../tmp/' + 'feat_checked_ohe.pkl'\n",
    "if not os.path.isfile(model_file):\n",
    "    print(\"Savind ohe list...\")\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(feat_checked, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subaevdi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV  8.370612\n",
      "X143 del 8.37 8.37 delta = 0.001\n",
      "X342 add 8.37 8.37 delta = -0.001\n",
      "X343 del 8.37 8.36 delta = 0.004\n",
      "X355 add 8.36 8.37 delta = -0.002\n",
      "X22 add 8.36 8.37 delta = -0.002\n",
      "X133 add 8.36 8.37 delta = -0.002\n",
      "X13 add 8.36 8.37 delta = -0.002\n",
      "X223 add 8.36 8.37 delta = -0.002\n",
      "X249 add 8.36 8.37 delta = -0.002\n",
      "X284 add 8.36 8.37 delta = -0.002\n",
      "X152 add 8.36 8.37 delta = -0.002\n",
      "X27 add 8.36 8.37 delta = -0.003\n",
      "X114 del 8.36 8.36 delta = 0.001\n",
      "X75 add 8.36 8.37 delta = -0.002\n",
      "X51 del 8.36 8.36 delta = 0.002\n",
      "X356 add 8.36 8.36 delta = -0.003\n",
      "X77 add 8.36 8.36 delta = -0.001\n",
      "X35 del 8.36 8.36 delta = 0.001\n",
      "X336 add 8.36 8.37 delta = -0.003\n",
      "X367 add 8.36 8.36 delta = -0.000\n",
      "X138 add 8.36 8.36 delta = -0.000\n",
      "X120 del 8.37 8.36 delta = 0.002\n",
      "X174 add 8.36 8.36 delta = -0.000\n",
      "X340 add 8.36 8.37 delta = -0.003\n",
      "X211 add 8.36 8.36 delta = -0.001\n",
      "X161 add 8.36 8.37 delta = -0.003\n",
      "X127 add 8.36 8.37 delta = -0.007\n",
      "X85 add 8.36 8.37 delta = -0.003\n",
      "X177 add 8.36 8.36 delta = -0.000\n",
      "X70 add 8.36 8.37 delta = -0.002\n",
      "X316 add 8.36 8.37 delta = -0.002\n",
      "X171 add 8.36 8.37 delta = -0.002\n",
      "X201 add 8.36 8.36 delta = -0.002\n",
      "X346 add 8.36 8.37 delta = -0.003\n",
      "X251 add 8.36 8.36 delta = -0.002\n",
      "X313 add 8.36 8.37 delta = -0.003\n",
      "X196 add 8.36 8.36 delta = -0.001\n",
      "X286 add 8.36 8.37 delta = -0.002\n",
      "X219 add 8.36 8.36 delta = -0.001\n",
      "X98 add 8.36 8.37 delta = -0.002\n",
      "X231 add 8.36 8.36 delta = -0.001\n",
      "X327 add 8.36 8.37 delta = -0.003\n",
      "X373 add 8.36 8.36 delta = -0.001\n",
      "X238 add 8.36 8.37 delta = -0.002\n",
      "X315 add 8.36 8.38 delta = -0.013\n",
      "X18 add 8.36 8.36 delta = -0.001\n",
      "X163 del 8.36 8.36 delta = 0.002\n",
      "X186 add 8.36 8.36 delta = -0.001\n",
      "X376 add 8.36 8.36 delta = -0.002\n",
      "X175 add 8.36 8.36 delta = -0.000\n",
      "X136 add 8.36 8.36 delta = -0.000\n",
      "X99 add 8.36 8.36 delta = -0.002\n",
      "X349 add 8.36 8.36 delta = -0.002\n",
      "X362 add 8.36 8.36 delta = -0.001\n",
      "X50 add 8.36 8.36 delta = -0.002\n",
      "X79 del 8.36 8.36 delta = 0.000\n",
      "X334 add 8.36 8.36 delta = -0.002\n",
      "X116 del 8.36 8.36 delta = 0.002\n",
      "X217 add 8.36 8.36 delta = -0.001\n",
      "X224 add 8.36 8.36 delta = -0.001\n",
      "X363 add 8.36 8.37 delta = -0.009\n",
      "X300 del 8.37 8.37 delta = 0.003\n",
      "X49 del 8.37 8.37 delta = 0.002\n",
      "X12 add 8.37 8.37 delta = -0.007\n",
      "X203 add 8.37 8.37 delta = -0.004\n",
      "X155 add 8.37 8.37 delta = -0.006\n",
      "X150 add 8.37 8.37 delta = -0.006\n",
      "X197 add 8.37 8.37 delta = -0.005\n",
      "X331 add 8.37 8.37 delta = -0.005\n",
      "X206 add 8.37 8.37 delta = -0.005\n",
      "X323 add 8.37 8.37 delta = -0.005\n",
      "X255 add 8.37 8.37 delta = -0.005\n",
      "X272 add 8.37 8.37 delta = -0.005\n",
      "X189 del 8.37 8.36 delta = 0.005\n",
      "X178 del 8.36 8.36 delta = 0.001\n",
      "X14 add 8.36 8.36 delta = -0.002\n",
      "X47 add 8.36 8.37 delta = -0.008\n",
      "X237 del 8.36 8.36 delta = 0.001\n",
      "X291 add 8.36 8.36 delta = -0.001\n",
      "X82 add 8.36 8.36 delta = -0.000\n",
      "X274 del 8.36 8.36 delta = 0.001\n",
      "X84 add 8.36 8.36 delta = -0.002\n",
      "X154 del 8.36 8.36 delta = 0.001\n",
      "X185 add 8.36 8.36 delta = -0.002\n",
      "X350 add 8.36 8.36 delta = -0.001\n",
      "X359 add 8.36 8.36 delta = -0.000\n",
      "X292 add 8.36 8.36 delta = -0.001\n",
      "X377 add 8.36 8.36 delta = -0.001\n",
      "X374 add 8.36 8.36 delta = -0.001\n",
      "X180 add 8.36 8.36 delta = -0.002\n",
      "X301 add 8.36 8.36 delta = -0.001\n",
      "X215 add 8.36 8.36 delta = -0.002\n",
      "X126 add 8.36 8.36 delta = -0.002\n",
      "X195 add 8.36 8.36 delta = -0.001\n",
      "X375 add 8.36 8.36 delta = -0.002\n",
      "X61 add 8.36 8.36 delta = -0.000\n",
      "X276 add 8.36 8.36 delta = -0.002\n",
      "X109 add 8.36 8.36 delta = -0.002\n",
      "X157 add 8.36 8.36 delta = -0.002\n",
      "X137 add 8.36 8.36 delta = -0.001\n",
      "X256 add 8.36 8.36 delta = -0.000\n",
      "X23 add 8.36 8.36 delta = -0.001\n",
      "X352 add 8.36 8.36 delta = -0.001\n",
      "X228 add 8.36 8.36 delta = -0.001\n",
      "X314 del 8.36 8.36 delta = 0.001\n",
      "X246 del 8.36 8.36 delta = 0.000\n",
      "X100 add 8.36 8.36 delta = -0.002\n",
      "X32 add 8.36 8.36 delta = -0.003\n",
      "X368 add 8.36 8.36 delta = -0.003\n",
      "X354 add 8.36 8.36 delta = -0.002\n",
      "X20 add 8.36 8.36 delta = -0.003\n",
      "X58 add 8.36 8.36 delta = -0.003\n",
      "X169 add 8.36 8.36 delta = -0.003\n",
      "X351 add 8.36 8.36 delta = -0.002\n",
      "X225 add 8.36 8.36 delta = -0.001\n",
      "X115 add 8.36 8.36 delta = -0.003\n",
      "X182 add 8.36 8.36 delta = -0.003\n",
      "X345 add 8.36 8.36 delta = -0.003\n"
     ]
    }
   ],
   "source": [
    "columns = feat_numb\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = df[ix_train]\n",
    "\n",
    "num_boost_rounds = 1500\n",
    "    \n",
    "xgb_params = { \n",
    "    'eta': 0.01,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.9,\n",
    "    'min_child_weight': 20,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'maximize':False,\n",
    "    'base_score': np.mean(y_train), # base prediction = mean(target)\n",
    "    'silent': 1,\n",
    "    'tree_method':'hist',\n",
    "    'seed':42,\n",
    "#    'gamma': 0.05,\n",
    "    'alpha':0.1\n",
    "}\n",
    "\n",
    "feat_checked = list()\n",
    "dtrain = xgb.DMatrix(X[columns], y)\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_rounds)\n",
    "t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "rmse = t.iloc[-1,0]\n",
    "\n",
    "print('CV ', t.iloc[-1,0])\n",
    "imp = model.get_fscore()\n",
    "feat_model = list(pd.DataFrame({'feat':list(imp.keys()),  'imp':list(imp.values())},\n",
    "             ).sort_values('imp')['feat'].values)\n",
    "feat_current = list(set(feat_model) - set(feat_checked))\n",
    "\n",
    "\n",
    "while len(feat_current) > 0:\n",
    "    # \n",
    "    dtrain = xgb.DMatrix(X[feat_checked + feat_current], y)\n",
    "    model = xgb.train(xgb_params, dtrain, num_boost_rounds)\n",
    "    t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    rmse = t.iloc[-1,0]\n",
    "    \n",
    "    imp = model.get_fscore()\n",
    "    feat_model = list(pd.DataFrame({'feat':list(imp.keys()),  'imp':list(imp.values())},\n",
    "                 ).sort_values('imp')['feat'].values)\n",
    "    feat_current = list(set(feat_model) - set(feat_checked))\n",
    "    feat = feat_current[0]\n",
    "    \n",
    "    # Проверка без признака\n",
    "    dtrain = xgb.DMatrix(X[feat_checked + feat_current[1:]], y)\n",
    "    t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    rmse_new = t.iloc[-1,0]\n",
    "\n",
    "    if rmse_new <= rmse:\n",
    "        print(feat, 'del {:.2f} {:.2f} delta = {:.3f}'.format(rmse, rmse_new, rmse - rmse_new))\n",
    "        feat_current = feat_current[1:]\n",
    "    else:\n",
    "        print(feat, 'add {:.2f} {:.2f} delta = {:.3f}'.format(rmse, rmse_new, rmse - rmse_new))\n",
    "        feat_checked.append(feat)\n",
    "        feat_current = feat_current[1:]\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = './../tmp/' + 'feat_checked_numb.pkl'\n",
    "if not os.path.isfile(model_file):\n",
    "    print(\"Savind ohe list...\")\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(feat_checked, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./../tmp/' + 'feat_checked_numb.pkl', 'rb') as f:\n",
    "    feat_checked_numb = pickle.load(f)\n",
    "    \n",
    "with open('./../tmp/' + 'feat_checked_ohe.pkl', 'rb') as f:\n",
    "    feat_checked_ohe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = feat_checked_numb + feat_checked_ohe\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = df[ix_train]\n",
    "\n",
    "num_boost_rounds = 1500\n",
    "    \n",
    "xgb_params = { \n",
    "    'eta': 0.01,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.9,\n",
    "    'min_child_weight': 20,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'maximize':False,\n",
    "    'base_score': np.mean(y_train), # base prediction = mean(target)\n",
    "    'silent': 1,\n",
    "    'tree_method':'hist',\n",
    "    'seed':42,\n",
    "#    'gamma': 0.05,\n",
    "    'alpha':0.1\n",
    "}\n",
    "\n",
    "feat_checked = list()\n",
    "dtrain = xgb.DMatrix(X[columns], y)\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_rounds)\n",
    "t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "rmse = t.iloc[-1,0]\n",
    "\n",
    "print('CV ', t.iloc[-1,0])\n",
    "imp = model.get_fscore()\n",
    "feat_model = list(pd.DataFrame({'feat':list(imp.keys()),  'imp':list(imp.values())},\n",
    "             ).sort_values('imp')['feat'].values)\n",
    "feat_current = list(set(feat_model) - set(feat_checked))\n",
    "\n",
    "\n",
    "while len(feat_current) > 0:\n",
    "    # \n",
    "    dtrain = xgb.DMatrix(X[feat_checked + feat_current], y)\n",
    "    model = xgb.train(xgb_params, dtrain, num_boost_rounds)\n",
    "    t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    rmse = t.iloc[-1,0]\n",
    "    \n",
    "    imp = model.get_fscore()\n",
    "    feat_model = list(pd.DataFrame({'feat':list(imp.keys()),  'imp':list(imp.values())},\n",
    "                 ).sort_values('imp')['feat'].values)\n",
    "    feat_current = list(set(feat_model) - set(feat_checked))\n",
    "    feat = feat_current[0]\n",
    "    \n",
    "    # Проверка без признака\n",
    "    dtrain = xgb.DMatrix(X[feat_checked + feat_current[1:]], y)\n",
    "    t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    rmse_new = t.iloc[-1,0]\n",
    "\n",
    "    if rmse_new <= rmse:\n",
    "        print(feat, 'del {:.2f} {:.2f} delta = {:.3f}'.format(rmse, rmse_new, rmse - rmse_new))\n",
    "        feat_current = feat_current[1:]\n",
    "    else:\n",
    "        print(feat, 'add {:.2f} {:.2f} delta = {:.3f}'.format(rmse, rmse_new, rmse - rmse_new))\n",
    "        feat_checked.append(feat)\n",
    "        feat_current = feat_current[1:]\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = './../tmp/' + 'feat_checked_numb_ohe.pkl'\n",
    "if not os.path.isfile(model_file):\n",
    "    print(\"Savind ohe list...\")\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(feat_checked, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X342',\n",
       " 'X355',\n",
       " 'X22',\n",
       " 'X223',\n",
       " 'X284',\n",
       " 'X152',\n",
       " 'ohe_181',\n",
       " 'X27',\n",
       " 'ohe_57',\n",
       " 'X75',\n",
       " 'ohe_73',\n",
       " 'ohe_189',\n",
       " 'X356',\n",
       " 'ohe_144',\n",
       " 'X77',\n",
       " 'ohe_187',\n",
       " 'X336',\n",
       " 'ohe_177',\n",
       " 'X138',\n",
       " 'ohe_142',\n",
       " 'X174',\n",
       " 'X340',\n",
       " 'X211',\n",
       " 'X161',\n",
       " 'X127',\n",
       " 'X85',\n",
       " 'X177',\n",
       " 'X70',\n",
       " 'ohe_80',\n",
       " 'ohe_53',\n",
       " 'ohe_135',\n",
       " 'X316',\n",
       " 'ohe_79',\n",
       " 'ohe_200',\n",
       " 'X171',\n",
       " 'X201',\n",
       " 'ohe_46',\n",
       " 'X251',\n",
       " 'X313',\n",
       " 'ohe_110',\n",
       " 'X196',\n",
       " 'X286',\n",
       " 'X219',\n",
       " 'ohe_52',\n",
       " 'ohe_89',\n",
       " 'ohe_54',\n",
       " 'X98',\n",
       " 'ohe_50',\n",
       " 'X231',\n",
       " 'ohe_60',\n",
       " 'X327',\n",
       " 'X373',\n",
       " 'X238',\n",
       " 'X315',\n",
       " 'X18',\n",
       " 'X186',\n",
       " 'X376',\n",
       " 'X175',\n",
       " 'X136',\n",
       " 'ohe_184',\n",
       " 'ohe_134',\n",
       " 'X363',\n",
       " 'X12',\n",
       " 'X203',\n",
       " 'ohe_56',\n",
       " 'X155',\n",
       " 'X150',\n",
       " 'X197',\n",
       " 'X331',\n",
       " 'ohe_204',\n",
       " 'X206',\n",
       " 'ohe_191',\n",
       " 'ohe_8',\n",
       " 'X323',\n",
       " 'ohe_10',\n",
       " 'X255',\n",
       " 'X272',\n",
       " 'ohe_160',\n",
       " 'X14',\n",
       " 'X47',\n",
       " 'X291',\n",
       " 'X82',\n",
       " 'ohe_75',\n",
       " 'ohe_163',\n",
       " 'X84',\n",
       " 'X185',\n",
       " 'ohe_176',\n",
       " 'X350',\n",
       " 'X359',\n",
       " 'X292',\n",
       " 'X377',\n",
       " 'X374',\n",
       " 'X180',\n",
       " 'X301',\n",
       " 'X215',\n",
       " 'X126',\n",
       " 'ohe_197',\n",
       " 'X375',\n",
       " 'X61',\n",
       " 'X276',\n",
       " 'X109',\n",
       " 'X157',\n",
       " 'X137',\n",
       " 'X256',\n",
       " 'X23',\n",
       " 'X352',\n",
       " 'ohe_180',\n",
       " 'ohe_196',\n",
       " 'X354',\n",
       " 'X20',\n",
       " 'X58',\n",
       " 'X169',\n",
       " 'ohe_165',\n",
       " 'X50',\n",
       " 'X351',\n",
       " 'X225',\n",
       " 'X115',\n",
       " 'X182',\n",
       " 'X334',\n",
       " 'ohe_208',\n",
       " 'X224',\n",
       " 'X217',\n",
       " 'X345',\n",
       " 'X311',\n",
       " 'X279',\n",
       " 'ohe_169',\n",
       " 'ohe_183',\n",
       " 'ohe_99',\n",
       " 'X222',\n",
       " 'X305',\n",
       " 'ohe_36',\n",
       " 'ohe_132',\n",
       " 'X338',\n",
       " 'ohe_148',\n",
       " 'ohe_40',\n",
       " 'X159',\n",
       " 'X56',\n",
       " 'X202',\n",
       " 'X220',\n",
       " 'ohe_32',\n",
       " 'ohe_41',\n",
       " 'X187',\n",
       " 'X337',\n",
       " 'X232',\n",
       " 'X129',\n",
       " 'X119',\n",
       " 'X261',\n",
       " 'X142',\n",
       " 'X81',\n",
       " 'X34',\n",
       " 'X229',\n",
       " 'X158',\n",
       " 'X226',\n",
       " 'X234',\n",
       " 'X322',\n",
       " 'X221',\n",
       " 'X348',\n",
       " 'X164',\n",
       " 'ohe_136',\n",
       " 'X117',\n",
       " 'X321',\n",
       " 'X170',\n",
       " 'ohe_149',\n",
       " 'X78',\n",
       " 'X139',\n",
       " 'X132',\n",
       " 'X267',\n",
       " 'ohe_186',\n",
       " 'X265',\n",
       " 'X168',\n",
       " 'X19',\n",
       " 'ohe_199',\n",
       " 'X31',\n",
       " 'X275',\n",
       " 'ohe_182',\n",
       " 'ohe_66',\n",
       " 'X294',\n",
       " 'X176',\n",
       " 'X151',\n",
       " 'X135',\n",
       " 'ohe_69',\n",
       " 'X131',\n",
       " 'ohe_49',\n",
       " 'X358',\n",
       " 'ohe_166',\n",
       " 'X324',\n",
       " 'ohe_203',\n",
       " 'X333',\n",
       " 'ohe_190',\n",
       " 'X106',\n",
       " 'X173',\n",
       " 'X148',\n",
       " 'X37',\n",
       " 'ohe_151',\n",
       " 'X341',\n",
       " 'ohe_45',\n",
       " 'X71',\n",
       " 'X38',\n",
       " 'X250',\n",
       " 'X287',\n",
       " 'ohe_24',\n",
       " 'X156',\n",
       " 'ohe_11',\n",
       " 'X361',\n",
       " 'X283',\n",
       " 'X141',\n",
       " 'X144',\n",
       " 'X118',\n",
       " 'X241',\n",
       " 'X382',\n",
       " 'ohe_202',\n",
       " 'X55',\n",
       " 'X247',\n",
       " 'X244',\n",
       " 'ohe_170',\n",
       " 'X73',\n",
       " 'ohe_122',\n",
       " 'X68',\n",
       " 'ohe_51',\n",
       " 'X96',\n",
       " 'X46',\n",
       " 'X326',\n",
       " 'X103',\n",
       " 'X273',\n",
       " 'X181',\n",
       " 'ohe_74',\n",
       " 'ohe_195',\n",
       " 'X209',\n",
       " 'X43',\n",
       " 'X329',\n",
       " 'X344',\n",
       " 'X45']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.54 ms\n"
     ]
    }
   ],
   "source": [
    "feat_checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subaevdi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X[feat_checked], y)\n",
    "t = xgb.cv(xgb_params, dtrain, num_boost_rounds, folds=kf, early_stopping_rounds=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.615624</td>\n",
       "      <td>0.412270</td>\n",
       "      <td>12.609231</td>\n",
       "      <td>0.212080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.553581</td>\n",
       "      <td>0.417373</td>\n",
       "      <td>12.546404</td>\n",
       "      <td>0.210782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.483966</td>\n",
       "      <td>0.419118</td>\n",
       "      <td>12.476195</td>\n",
       "      <td>0.212398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.415727</td>\n",
       "      <td>0.420801</td>\n",
       "      <td>12.407793</td>\n",
       "      <td>0.213853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.348433</td>\n",
       "      <td>0.423057</td>\n",
       "      <td>12.339736</td>\n",
       "      <td>0.214982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.282219</td>\n",
       "      <td>0.424846</td>\n",
       "      <td>12.273081</td>\n",
       "      <td>0.216503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.216516</td>\n",
       "      <td>0.426483</td>\n",
       "      <td>12.206710</td>\n",
       "      <td>0.218414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.151707</td>\n",
       "      <td>0.428483</td>\n",
       "      <td>12.141372</td>\n",
       "      <td>0.220042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.090716</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>12.079088</td>\n",
       "      <td>0.219444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.028369</td>\n",
       "      <td>0.434944</td>\n",
       "      <td>12.015707</td>\n",
       "      <td>0.221106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.966483</td>\n",
       "      <td>0.437071</td>\n",
       "      <td>11.953258</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.905772</td>\n",
       "      <td>0.438786</td>\n",
       "      <td>11.891935</td>\n",
       "      <td>0.224275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>8.321202</td>\n",
       "      <td>0.683778</td>\n",
       "      <td>8.016864</td>\n",
       "      <td>0.365031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>8.321261</td>\n",
       "      <td>0.683976</td>\n",
       "      <td>8.016111</td>\n",
       "      <td>0.364849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>8.321053</td>\n",
       "      <td>0.683745</td>\n",
       "      <td>8.015285</td>\n",
       "      <td>0.365041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>8.320788</td>\n",
       "      <td>0.683696</td>\n",
       "      <td>8.014707</td>\n",
       "      <td>0.365095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>8.320578</td>\n",
       "      <td>0.683667</td>\n",
       "      <td>8.014031</td>\n",
       "      <td>0.364978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>8.320697</td>\n",
       "      <td>0.683469</td>\n",
       "      <td>8.012997</td>\n",
       "      <td>0.365097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8.320604</td>\n",
       "      <td>0.683359</td>\n",
       "      <td>8.012545</td>\n",
       "      <td>0.365077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>8.320323</td>\n",
       "      <td>0.683203</td>\n",
       "      <td>8.011872</td>\n",
       "      <td>0.365205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>8.320563</td>\n",
       "      <td>0.683122</td>\n",
       "      <td>8.011158</td>\n",
       "      <td>0.365358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>8.320334</td>\n",
       "      <td>0.683126</td>\n",
       "      <td>8.010269</td>\n",
       "      <td>0.365078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>8.320136</td>\n",
       "      <td>0.683004</td>\n",
       "      <td>8.009473</td>\n",
       "      <td>0.365221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>8.319967</td>\n",
       "      <td>0.682944</td>\n",
       "      <td>8.008555</td>\n",
       "      <td>0.365319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0         12.615624       0.412270        12.609231        0.212080\n",
       "1         12.553581       0.417373        12.546404        0.210782\n",
       "2         12.483966       0.419118        12.476195        0.212398\n",
       "3         12.415727       0.420801        12.407793        0.213853\n",
       "4         12.348433       0.423057        12.339736        0.214982\n",
       "5         12.282219       0.424846        12.273081        0.216503\n",
       "6         12.216516       0.426483        12.206710        0.218414\n",
       "7         12.151707       0.428483        12.141372        0.220042\n",
       "8         12.090716       0.432711        12.079088        0.219444\n",
       "9         12.028369       0.434944        12.015707        0.221106\n",
       "10        11.966483       0.437071        11.953258        0.222500\n",
       "11        11.905772       0.438786        11.891935        0.224275\n",
       "..              ...            ...              ...             ...\n",
       "418        8.321202       0.683778         8.016864        0.365031\n",
       "419        8.321261       0.683976         8.016111        0.364849\n",
       "420        8.321053       0.683745         8.015285        0.365041\n",
       "421        8.320788       0.683696         8.014707        0.365095\n",
       "422        8.320578       0.683667         8.014031        0.364978\n",
       "423        8.320697       0.683469         8.012997        0.365097\n",
       "424        8.320604       0.683359         8.012545        0.365077\n",
       "425        8.320323       0.683203         8.011872        0.365205\n",
       "426        8.320563       0.683122         8.011158        0.365358\n",
       "427        8.320334       0.683126         8.010269        0.365078\n",
       "428        8.320136       0.683004         8.009473        0.365221\n",
       "429        8.319967       0.682944         8.008555        0.365319\n",
       "\n",
       "[430 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.9 ms\n"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
