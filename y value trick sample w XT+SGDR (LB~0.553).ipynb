{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y value trick from but using median\n",
    "#https://www.kaggle.com/robertoruiz/a-magic-feature/code\n",
    "#https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34180\n",
    "#referancing random_projection and decomposition from\n",
    "#https://www.kaggle.com/hakeem/stacked-then-averaged-models-0-5697\n",
    "\n",
    "import time\n",
    "from random import choice, sample, shuffle, uniform, seed\n",
    "from math import exp, expm1, log1p, log10, log2, sqrt, ceil, floor\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#\n",
    "from sklearn.decomposition import TruncatedSVD, PCA, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_id, target = 'ID', 'y'\n",
    "###############################################################################\n",
    "\n",
    "def set_decompostions(tfs={}, n_comp=12, random_seed=622):\n",
    "    # tSVD\n",
    "    tfs['svd'] = TruncatedSVD(n_components=n_comp, random_state=random_seed)\n",
    "    # PCA\n",
    "    tfs['pca'] = PCA(n_components=n_comp, random_state=random_seed)\n",
    "    # ICA\n",
    "    tfs['ica'] = FastICA(n_components=n_comp, max_iter=1000, random_state=random_seed)\n",
    "    # GRP\n",
    "    tfs['grp'] = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=random_seed)\n",
    "    # SRP\n",
    "    tfs['srp'] = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=random_seed)\n",
    "    \n",
    "    return tfs\n",
    "\n",
    "###############################################################################\n",
    "def collect_predict(preds, collect, d=1., col='y_', opt_test=False):\n",
    "    if opt_test:\n",
    "        if col not in collect.columns:\n",
    "            collect[col] = 0.\n",
    "        collect[col] += preds / d\n",
    "    else:        \n",
    "        collect[col] = preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: X_train: (4209, 378)\n",
      "original data: X_test: (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "options = {}\n",
    "nr_splits = 10\n",
    "fold_gen_seed = 622\n",
    "tmstmp = '{}'.format(time.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "\n",
    "#load data\n",
    "input_folder = '../data/'\n",
    "#train\n",
    "df_train = pd.read_csv(input_folder + 'train.csv')\n",
    "print(\"original data: X_train: {}\".format(df_train.shape), flush=True)\n",
    "df_train['Xid'] = df_train[target_id].apply(log1p)\n",
    "#test\n",
    "df_test = pd.read_csv(input_folder + 'test.csv')\n",
    "print(\"original data: X_test: {}\".format(df_test.shape), flush=True)\n",
    "df_test['Xid'] = df_test[target_id].apply(log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 377 features\n",
      "X2 is object: 50 uniques\n",
      "X1 is object: 27 uniques\n",
      "X0 is object: 53 uniques\n",
      "X6 is object: 12 uniques\n",
      "X3 is object: 7 uniques\n",
      "X4 is object: 4 uniques\n",
      "X8 is object: 25 uniques\n",
      "X5 is object: 33 uniques\n"
     ]
    }
   ],
   "source": [
    "#factorized\n",
    "f_magic = ['X0', 'X2']\n",
    "feats = list(set(df_train.columns.tolist()).difference([target, target_id]))\n",
    "print('read in {} features'.format(len(feats)), flush=True)\n",
    "for c in feats:\n",
    "    if df_train[c].dtype == 'object':\n",
    "        candidates = list(df_train[c].values) + list(df_test[c].values)\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(candidates)\n",
    "        df_train[c] = lbl.transform(list(df_train[c].values))\n",
    "        df_test[c] = lbl.transform(list(df_test[c].values))\n",
    "        val_uniq = len(set(candidates))\n",
    "        print('{} is object: {} uniques'.format(c, val_uniq), flush=True)\n",
    "\n",
    "#data\n",
    "train_X = df_train[feats]\n",
    "test_X = df_test[feats]\n",
    "\n",
    "#id\n",
    "train_id = df_train[target_id]\n",
    "test_id = df_test[target_id]\n",
    "\n",
    "#capping\n",
    "train_y = df_train[target]\n",
    "raw_train_y = df_train[target]\n",
    "\n",
    "#fold assignments\n",
    "train_sets, valid_sets = list(), list()\n",
    "fold_gen = KFold(n_splits=nr_splits, shuffle=True, random_state=fold_gen_seed)\n",
    "for train_indices, valid_indices in fold_gen.split(train_y, train_y):\n",
    "    train_sets.append(train_indices)\n",
    "    valid_sets.append(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regressor\n",
    "seed_val =170623\n",
    "#glm\n",
    "a = 0.0005\n",
    "l1r = 0.25\n",
    "eps = 0.03\n",
    "glm = SGDRegressor(loss='huber', penalty='elasticnet', alpha=a, l1_ratio=l1r, fit_intercept=True,\n",
    "                   shuffle=True, verbose=0, epsilon=eps, random_state=seed_val, learning_rate='invscaling',\n",
    "                   eta0=0.01, power_t=0.25, warm_start=False, average=False)\n",
    "#extratree\n",
    "xt = ExtraTreesRegressor(n_estimators=1200, criterion='mse', max_depth=None, min_samples_split=4,\n",
    "                         min_samples_leaf=4, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                         max_leaf_nodes=128, bootstrap=True, oob_score=True, n_jobs=-1,\n",
    "                         random_state=seed_val, verbose=0, warm_start=False)\n",
    "\n",
    "#decompositions\n",
    "nb_comp = 12\n",
    "tfs = set_decompostions(n_comp=nb_comp, random_seed=623)\n",
    "\n",
    "#feats\n",
    "f_cat = list(set(df_train.columns.tolist()).difference([target, target_id]))\n",
    "\n",
    "#data\n",
    "train_X = df_train[f_cat]\n",
    "test_X = df_test[f_cat]\n",
    "\n",
    "#preds\n",
    "train_preds = pd.DataFrame()\n",
    "test_preds = pd.DataFrame()\n",
    "test_preds[target_id] = test_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X0', 'X2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold cv\n",
      "eval fold 00\n",
      "XT r2=0.586677\n",
      "SGDR r2=0.577821\n",
      "\n",
      "eval fold 01\n",
      "XT r2=0.523746\n",
      "SGDR r2=0.523233\n",
      "\n",
      "eval fold 02\n",
      "XT r2=0.476042\n",
      "SGDR r2=0.475179\n",
      "\n",
      "eval fold 03\n",
      "XT r2=0.603464\n",
      "SGDR r2=0.486556\n",
      "\n",
      "eval fold 04\n",
      "XT r2=0.603788\n",
      "SGDR r2=0.482907\n",
      "\n",
      "eval fold 05\n",
      "XT r2=0.634381\n",
      "SGDR r2=0.585052\n",
      "\n",
      "eval fold 06\n",
      "XT r2=0.598894\n",
      "SGDR r2=0.560769\n",
      "\n",
      "eval fold 07\n",
      "XT r2=0.616611\n",
      "SGDR r2=0.593856\n",
      "\n",
      "eval fold 08\n",
      "XT r2=0.586899\n",
      "SGDR r2=0.586663\n",
      "\n",
      "eval fold 09\n",
      "XT r2=0.389999\n",
      "SGDR r2=0.367116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#start cv\n",
    "print('\\n{}-fold cv'.format(nr_splits))\n",
    "for nr_fold in range(nr_splits):\n",
    "    print('eval fold {:02d}'.format(nr_fold), flush=True)\n",
    "\n",
    "    #data\n",
    "    X_train = train_X.iloc[train_sets[nr_fold]].reset_index(drop=True)\n",
    "    X_valid = train_X.iloc[valid_sets[nr_fold]].reset_index(drop=True)\n",
    "    X_test = test_X.copy()\n",
    "    #y\n",
    "    y_train = train_y.iloc[train_sets[nr_fold]].reset_index(drop=True)\n",
    "    y_valid = train_y.iloc[valid_sets[nr_fold]].reset_index(drop=True)\n",
    "    raw_y_valid = raw_train_y.iloc[valid_sets[nr_fold]].reset_index(drop=True)\n",
    "\n",
    "    #pred\n",
    "    sub_train = pd.DataFrame()\n",
    "    sub_train[target_id] = train_id.iloc[valid_sets[nr_fold]].tolist()\n",
    "\n",
    "    #using transformer\n",
    "    for k, v in tfs.items():\n",
    "        trans_train = v.fit_transform(X_train)\n",
    "        trans_valid = v.transform(X_valid)\n",
    "        trans_test = v.transform(X_test)\n",
    "        for nb in range(nb_comp):\n",
    "            new_col = '{}_{:02d}'.format(k, nb+1)\n",
    "            X_train[new_col] = trans_train[:, nb]\n",
    "            X_valid[new_col] = trans_valid[:, nb]\n",
    "            X_test[new_col] = trans_test[:, nb]\n",
    "\n",
    "    #magic\n",
    "    raw_y_train = raw_train_y.iloc[train_sets[nr_fold]].reset_index(drop=True)\n",
    "    for f in f_magic:\n",
    "        magic_df = pd.DataFrame()\n",
    "        magic_df[target] = raw_y_train\n",
    "        magic_df[f] = df_train[f].iloc[train_sets[nr_fold]].reset_index(drop=True)\n",
    "        rplc = np.median(raw_y_train)\n",
    "        magic_df = magic_df.groupby(f)[target].median()\n",
    "        magic_dict = magic_df.to_dict()\n",
    "\n",
    "        f_m = 'magic_{}'.format(f)\n",
    "        X_train[f_m] = X_train[f].apply(lambda x: magic_dict.get(x, rplc))\n",
    "        X_valid[f_m] = X_valid[f].apply(lambda x: magic_dict.get(x, rplc))\n",
    "        X_test[f_m] = X_test[f].apply(lambda x: magic_dict.get(x, rplc))\n",
    "\n",
    "    #clean NA\n",
    "    X_train = X_train.apply(np.nan_to_num)\n",
    "    X_valid = X_valid.apply(np.nan_to_num)\n",
    "    X_test = X_test.apply(np.nan_to_num)\n",
    "\n",
    "    #        \n",
    "    stem = 'xt'\n",
    "    target_this = 'y_{}'.format(stem)\n",
    "    reg = xt\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    preds = reg.predict(X_valid)\n",
    "    print('XT r2={:.6f}'.format(r2_score(y_valid, preds)), flush=True)\n",
    "    collect_predict(preds, sub_train, d=nr_splits, col=target_this, opt_test=False)\n",
    "    collect_predict(reg.predict(X_test), test_preds, d=nr_splits, col=target_this, opt_test=True)\n",
    "\n",
    "    #\n",
    "    stem = 'glm'\n",
    "    target_this = 'y_{}'.format(stem)\n",
    "    reg = glm\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    preds = reg.predict(X_valid)\n",
    "    print('SGDR r2={:.6f}'.format(r2_score(raw_y_valid, preds)))        \n",
    "    collect_predict(preds, sub_train, d=nr_splits, col=target_this, opt_test=False)\n",
    "    collect_predict(reg.predict(X_test), test_preds, d=nr_splits, col=target_this, opt_test=True)\n",
    "\n",
    "    #end of one fold eval in cv\n",
    "    train_preds = train_preds.append(sub_train)\n",
    "    del X_train, X_valid, X_test\n",
    "    print(end='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary\n",
      "xt r2 = 0.556426\n",
      "glm r2 = 0.518692\n",
      "optimizing weights\n",
      "no 0000: r2 = 0.55603, rmse = 31.601, current best ([0.46377034490797536, 0.5362296550920247])\n",
      "no 0001: r2 = 0.56127, rmse = 12.999, current best ([0.6430687844904928, 0.3569312155095073])\n",
      "no 0004: r2 = 0.56144, rmse = 8.366, current best ([0.6553264409234699, 0.3446735590765302])\n",
      "no 0009: r2 = 0.56162, rmse = 17.581, current best ([0.6704737517547947, 0.32952624824520527])\n",
      "no 0011: r2 = 0.56167, rmse = 9.357, current best ([0.6759924442497741, 0.3240075557502259])\n",
      "no 0033: r2 = 0.56175, rmse = 9.065, current best ([0.6842802135651429, 0.31571978643485704])\n",
      "no 0047: r2 = 0.56192, rmse = 8.941, current best ([0.7139540714395106, 0.2860459285604894])\n",
      "no 0122: r2 = 0.56196, rmse = 8.386, current best ([0.744978582298828, 0.2550214177011719])\n",
      "no 0744: r2 = 0.56196, rmse = 8.411, current best ([0.7441533384359903, 0.25584666156400976])\n",
      "w xt: 0.744153\n",
      "w glm: 0.255847\n"
     ]
    }
   ],
   "source": [
    "#merge y into dataset\n",
    "train_preds = train_preds.reset_index(drop=True)\n",
    "df_train = df_train.merge(train_preds, how='left', on=target_id)\n",
    "df_test = df_test.merge(test_preds, how='left', on=target_id)        \n",
    "\n",
    "#performance check\n",
    "print('summary')\n",
    "for t in train_preds.columns.tolist():\n",
    "    if t.startswith('y_'):\n",
    "        #score = r2_score(train_y, df_train[t])\n",
    "        score = r2_score(raw_train_y, df_train[t])\n",
    "        print('{} r2 = {:.6f}'.format(t[2:], score), flush=True)\n",
    "\n",
    "        sub = pd.DataFrame()\n",
    "        sub[target_id] = df_test[target_id]\n",
    "        sub[target] = df_test[t]\n",
    "        sub.to_csv(\"../submit/{}_{}_s{:.6f}.csv\".format(tmstmp, t[2:], score), index=False)\n",
    "\n",
    "#find best weights\n",
    "print('optimizing weights')\n",
    "trials, best = 1000, 0\n",
    "best_w = []\n",
    "for i in range(trials):\n",
    "    weights = []\n",
    "    df_train['tmp'] = 0\n",
    "\n",
    "    for t in train_preds.columns.tolist():\n",
    "        if t.startswith('y_'):\n",
    "            weights.append(uniform(0.25, 0.75))\n",
    "            df_train['tmp'] += df_train[t] * weights[-1]\n",
    "\n",
    "    s = sum(weights)\n",
    "    score = r2_score(raw_train_y, df_train['tmp'].apply(lambda x: x/s))\n",
    "    if score > best:\n",
    "        best = score\n",
    "        rmse = sqrt(mean_squared_error(raw_train_y, df_train['tmp']))\n",
    "        best_w = [w / s for w in weights]\n",
    "        print('no {:04d}: r2 = {:.5f}, rmse = {:.3f}, current best ({})'.format(i, best, rmse, best_w), flush=True)\n",
    "\n",
    "#save weighted \n",
    "sub = pd.DataFrame()\n",
    "sub[target_id] = df_test[target_id]    \n",
    "sub[target] = 0\n",
    "i = 0\n",
    "for t in train_preds.columns.tolist():\n",
    "    if t.startswith('y_'):\n",
    "        sub[target] += df_test[t] * best_w[i]\n",
    "        print('w {}: {:.6f}'.format(t[2:], best_w[i]), flush=True)\n",
    "        i += 1\n",
    "sub.to_csv(\"../submit/{}_wsum_s{:.6f}.csv\".format(tmstmp, best), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
